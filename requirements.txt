llama-cpp-python>=0.2.0
rich>=13.0.0
prompt-toolkit>=3.0.0
pyyaml>=6.0
requests>=2.28.0
typer>=0.9.0
watchdog>=3.0.0
pygments>=2.15.0